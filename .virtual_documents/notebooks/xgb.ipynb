# 一つ上の階層からモジュールを参照できるようにする
import sys
sys.path.append('..')


# ロギング用
import os
from datetime import datetime, timezone, timedelta
from logs.logger import create_logger
# モデル作成補助用
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from features.funcs import load_feather
from evals.funcs import get_pred_result, get_acc_and_logloss, print_conf_matrix
from inputs.funcs import load_data
# モデル作成用
import xgboost as xgb
from models.xgb import ModelXGB, ModelXGBSklearn
from keras.layers import Dense, Dropout
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold


# モジュールの変更を自動的に反映する
get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


# loggingの設定を行う
today = datetime.now(timezone(timedelta(hours=9)))
exp_version = today.strftime('%Y%m%d')
os.environ['exp_version'] = exp_version
create_logger(exp_version)


train_x, train_y, test_x = load_data()


train_x = train_x.drop(['Name', 'Cabin', 'Ticket'], axis=1)
test_x = test_x.drop(['Name', 'Cabin', 'Ticket'], axis=1)


base_path = '../features/'
train_x = load_feather(train_x, base_path + 'sex_train.feather', 'Sex')
test_x = load_feather(test_x, base_path + 'sex_test.feather', 'Sex')
train_x = load_feather(train_x, base_path + 'embarked_train.feather', 'Embarked')
test_x = load_feather(test_x, base_path + 'embarked_test.feather', 'Embarked')


model = ModelXGB(model_name='base_model', logging=True, verbose_eval=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)


get_acc_and_logloss(pred_train, train_y, logging=True)


train_x, train_y, test_x = load_data()


train_x = train_x.drop(['Name', 'Cabin', 'Ticket', 'Embarked'], axis=1)
test_x = test_x.drop(['Name', 'Cabin', 'Ticket', 'Embarked'], axis=1)


base_path = '../features/'
train_x = load_feather(train_x, base_path + 'sex_train.feather', 'Sex')
test_x = load_feather(test_x, base_path + 'sex_test.feather', 'Sex')


model = ModelXGB(model_name='without_emberked_col', logging=True, verbose_eval=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)


get_acc_and_logloss(pred_train, train_y, logging=True)


train_x, train_y, test_x = load_data()


train_x = train_x.drop(['Name', 'Cabin', 'Ticket'], axis=1)
test_x = test_x.drop(['Name', 'Cabin', 'Ticket'], axis=1)


base_path = '../features/'
train_x = load_feather(train_x, base_path + 'sex_train.feather', 'Sex')
test_x = load_feather(test_x, base_path + 'sex_test.feather', 'Sex')
train_x = load_feather(train_x, base_path + 'embarked_train.feather', 'Embarked')
test_x = load_feather(test_x, base_path + 'embarked_test.feather', 'Embarked')
train_x = load_feather(train_x, base_path + 'age_train.feather', 'AgeGroup')
test_x = load_feather(test_x, base_path + 'age_test.feather', 'AgeGroup')


model = ModelXGB(model_name='with_age_group_col', logging=True, verbose_eval=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)


get_acc_and_logloss(pred_train, train_y, logging=True)


xgb.plot_importance(model.get_model())


model = ModelXGB(num_round=15, model_name='with_age_group_col_and_more_num_rounds', logging=True, verbose_eval=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)


get_acc_and_logloss(pred_train, train_y, logging=True)


model = ModelXGBSklearn(n_estimators=15, learning_rate=0.2, model_name='sklearn', logging=True, verbose=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)
get_acc_and_logloss(pred_train, train_y, logging=True)


xgb.plot_importance(model.get_model())


model = ModelXGBSklearn(n_estimators=100, learning_rate=0.03, model_name='slearn', logging=True, verbose=False)
pred_train, preds_test = get_pred_result(model, train_x, train_y, test_x)
get_acc_and_logloss(pred_train, train_y, logging=True)


xgb.plot_importance(model.get_model())


model = ModelXGBSklearn(n_estimators=20, learning_rate=0.2, max_depth=None, model_name='sklearn_without_passenger_id', verbose=False, logging=True)
pred_train, preds_test = get_pred_result(model,
                                         train_x.drop('PassengerId', axis=1),
                                         train_y, test_x.drop('PassengerId', axis=1))
get_acc_and_logloss(pred_train, train_y, logging=True)


xgb.plot_importance(model.get_model())


params = {
    'objective':['binary:logistic'],
    'learning_rate': [0.025, 0.05, 0.1, 0.2, 0.3],
    'max_depth': [5, 10, 15, 20, 40, 60, 100],
    'silent': [1],
    'n_estimators': [5, 10, 15, 20, 40, 60, 100, 1000],
    'seed': [1]
}


model = xgb.XGBClassifier()
clf = GridSearchCV(model, params, n_jobs=5, scoring='accuracy', verbose=2, refit=False)
clf.fit(train_x, train_y)


clf.best_score_


clf.best_params_


clf_2 = GridSearchCV(model, params, n_jobs=5, scoring='accuracy', verbose=2, refit=False)
clf_2.fit(train_x.drop('PassengerId', axis=1), train_y)


clf_2.best_score_


clf_2.best_params_


best_params_lst = []
kf = KFold(n_splits=4, shuffle=True, random_state=1)

for tr_idx, va_idx in kf.split(train_x):
    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]
    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]
    
    model = xgb.XGBClassifier()
    clf_3 = GridSearchCV(model, params, n_jobs=5, scoring='accuracy', verbose=2, refit=False)
    clf_3.fit(tr_x.drop('PassengerId', axis=1), tr_y)

    best_params_lst.append({'best_params': clf_3.best_params_, 'best_score': clf_3.best_score_})


best_params_lst


print('learning_rate: 0.1/0.2')
print('max_depth: 5')
print('n_estimator: 5/60')


model = ModelXGBSklearn(n_estimators=5, learning_rate=0.2, max_depth=5,
                        model_name='grid_search', logging=True, verbose=False)
pred_train, preds_test = get_pred_result(model,
                                         train_x.drop('PassengerId', axis=1),
                                         train_y, test_x.drop('PassengerId', axis=1))
get_acc_and_logloss(pred_train, train_y, logging=True)


model = ModelXGBSklearn(n_estimators=60, learning_rate=0.1, max_depth=5,
                        model_name='grid_search', logging=True, verbose=False)
pred_train, preds_test = get_pred_result(model,
                                         train_x.drop('PassengerId', axis=1),
                                         train_y, test_x.drop('PassengerId', axis=1))
get_acc_and_logloss(pred_train, train_y, logging=True)


model = ModelXGBSklearn(n_estimators=100, learning_rate=0.1, max_depth=5,
                        model_name='grid_search', logging=True, verbose=False)
pred_train, preds_test = get_pred_result(model,
                                         train_x.drop('PassengerId', axis=1),
                                         train_y, test_x.drop('PassengerId', axis=1))
get_acc_and_logloss(pred_train, train_y, logging=True)


model = ModelXGBSklearn(n_estimators=40, learning_rate=0.2, max_depth=5,
                        model_name='grid_search', verbose=False, logging=True)
pred_train, preds_test = get_pred_result(model,
                                         train_x.drop('PassengerId', axis=1),
                                         train_y, test_x.drop('PassengerId', axis=1))
get_acc_and_logloss(pred_train, train_y, logging=True)


model = ModelXGBSklearn(n_estimators=60, learning_rate=0.1, max_depth=5,
                        model_name='submission', logging=False, verbose=False)
model.model.fit(train_x.drop('PassengerId', axis=1),
                train_y, eval_metric='logloss',
                eval_set=[(train_x.drop('PassengerId', axis=1), train_y)],
                verbose=False)


prediction = model.predict(test_x.drop('PassengerId', axis=1))


submission = pd.DataFrame({'PassengerId': test_x['PassengerId'].values, 'Survived': prediction})


submission_file_path = 'submissions/xgb_submission_{}.csv'.format(today.strftime('%Y%m%d'))
submission.to_csv(submission_file_path, index=False)



